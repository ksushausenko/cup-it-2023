{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Gx2d4ybQp12q",
        "rqXpsiovnnnW",
        "6S8QeTOgozU3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "@meoskis задачка тебе: поработать с датасетом\n",
        "попробуй загрузи его, проведи его базовый анализ, есть ли там пропуски, наличие спец символов и так далее\n",
        "ну и почитай как вообще анализировать такие текстовые датасеты, какие там могут быть метрики"
      ],
      "metadata": {
        "id": "mQ9va1P8nYDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Возникшие вопросы:\n",
        "\n",
        "1) При анализе комментров следует ли выбрасывать из рассмотрения ссылки (брать только текст комментария). С одной стороны в ссылке может быть нужное решения с правильными словами, когда текст комма будет не полным. С другой как убедится, что она допустим не фишинговая?"
      ],
      "metadata": {
        "id": "Gx2d4ybQp12q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Полезнеые ссылки:\n",
        "\n",
        "https://towardsdatascience.com/getting-started-with-text-analysis-in-python-ca13590eb4f7"
      ],
      "metadata": {
        "id": "rqXpsiovnnnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Информация о датасете:\n",
        "\n",
        "Данные содержат тренировочную (ranking_train.jsonl) и тестовую (ranking_test.jsonl) выборки.\n",
        "\n",
        "В каждом файле почти одинаковый формат:\n",
        "- Отдельная строчка в файле — валидный JSON с семплом\n",
        "- Каждый JSON имеет поле text с текстом поста и массив сomments из 5 элементов\n",
        "- Каждый элемент массива это словарь с ключами text с текстом комментария и score с позицией ранжирования (0 cоответствует самому популярному комментарию, 4 самому непопулярному)\n",
        "- В тестовом файле в поле score стоит null\n",
        "\n",
        "Заполните тестовую выборку, т.е. расставьте в файле ranking_test.jsonl вместо null значения score. В рамках одного семпла они должны быть от 0 до 4 и не должны повторяться.\n",
        "Пришлите файл с результатами вместе с кодом и презентацией.\n",
        "\n",
        "По валидации - будем смотреть на NDCG метрику (hint: она уже есть в библиотеке sklearn). \n",
        "В целом, хочется видеть рассуждения, поэтому можно предлагать и другие способы оценки."
      ],
      "metadata": {
        "id": "6S8QeTOgozU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Код"
      ],
      "metadata": {
        "id": "nzSv55zxo5_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyenchant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UxTSvpQLcmt",
        "outputId": "7c22038d-eca3-4e60-ce8d-4e24b93eca38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4822aV1smxRt"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import copy\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer\n",
        "from collections import Counter\n",
        "import re\n",
        "import html\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import words\n",
        "from textblob import TextBlob\n",
        "from gensim.models import FastText\n",
        "from sklearn.metrics import ndcg_score\n",
        "import string\n",
        "import enchant\n",
        "from scipy.stats import rankdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmtEtDkE8RF4",
        "outputId": "288a84f9-58ad-4c6f-91db-3b7d7872246a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLpblD5_uMcQ",
        "outputId": "72f50be5-9725-41eb-fe49-1ae854570460"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4XTXeHAuRxk",
        "outputId": "9b0055b9-0e4b-4902-f2db-b09cbd8421d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Als9UCAQ9MOs",
        "outputId": "51d7191d-126f-4647-869a-971e7fd6dd35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "FXlH6cWq9Yhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662b90b7-1524-4014-bb4a-55600bfb79e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIGiOuDDOapr",
        "outputId": "793c143d-31fd-4a0f-961a-6236fc5cd132"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_train = pd.read_json(\"/content/drive/MyDrive/case/ranking_train.jsonl\", lines=True)\n",
        "ranking_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0VWGcdqArTuT",
        "outputId": "d5b424c8-f9ea-4298-d226-9321b7042e22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  \\\n",
              "0      How many summer Y Combinator fundees decided n...   \n",
              "1                         CBS acquires last.fm for $280m   \n",
              "2                    How Costco Became the Anti-Wal-Mart   \n",
              "3      Fortune Favors Big Turds | Screw The Money, Th...   \n",
              "4      StartupWeekend: 70 Founders Create One Company...   \n",
              "...                                                  ...   \n",
              "88102  Don't upgrade to iOS 8.0.1 or you may experien...   \n",
              "88103  Ask HN: How do US HNers get their health insur...   \n",
              "88104                 Justin Gordon Using React on Rails   \n",
              "88105  iOS 8.0.1 released, broken on iPhone 6 models,...   \n",
              "88106  Pay your rent with a Credit or Debit card. No ...   \n",
              "\n",
              "                                                comments  \n",
              "0      [{'text': 'Going back to school is not identic...  \n",
              "1      [{'text': 'It will be curious to see where thi...  \n",
              "2      [{'text': 'I really hate it when people falsel...  \n",
              "3      [{'text': 'His real point is that something ca...  \n",
              "4      [{'text': 'Looks like someone hasn't read The ...  \n",
              "...                                                  ...  \n",
              "88102  [{'text': 'I had this issue and was able to fi...  \n",
              "88103  [{'text': 'We use a HSA-qualified high-deducti...  \n",
              "88104  [{'text': 'neat insight! A friend of mine conv...  \n",
              "88105  [{'text': 'Ouch, I feel for whoever let this s...  \n",
              "88106  [{'text': 'Most major banks offer a service ca...  \n",
              "\n",
              "[88107 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a7526f1-4290-4621-93d6-2d278947755f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>[{'text': 'Going back to school is not identic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CBS acquires last.fm for $280m</td>\n",
              "      <td>[{'text': 'It will be curious to see where thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How Costco Became the Anti-Wal-Mart</td>\n",
              "      <td>[{'text': 'I really hate it when people falsel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fortune Favors Big Turds | Screw The Money, Th...</td>\n",
              "      <td>[{'text': 'His real point is that something ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>StartupWeekend: 70 Founders Create One Company...</td>\n",
              "      <td>[{'text': 'Looks like someone hasn't read The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88102</th>\n",
              "      <td>Don't upgrade to iOS 8.0.1 or you may experien...</td>\n",
              "      <td>[{'text': 'I had this issue and was able to fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88103</th>\n",
              "      <td>Ask HN: How do US HNers get their health insur...</td>\n",
              "      <td>[{'text': 'We use a HSA-qualified high-deducti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88104</th>\n",
              "      <td>Justin Gordon Using React on Rails</td>\n",
              "      <td>[{'text': 'neat insight! A friend of mine conv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88105</th>\n",
              "      <td>iOS 8.0.1 released, broken on iPhone 6 models,...</td>\n",
              "      <td>[{'text': 'Ouch, I feel for whoever let this s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88106</th>\n",
              "      <td>Pay your rent with a Credit or Debit card. No ...</td>\n",
              "      <td>[{'text': 'Most major banks offer a service ca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88107 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a7526f1-4290-4621-93d6-2d278947755f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a7526f1-4290-4621-93d6-2d278947755f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a7526f1-4290-4621-93d6-2d278947755f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаг 1. Преобразование датафрейма\n",
        "\n",
        "ranking_train_exploded = ranking_train.explode('comments')\n",
        "ranking_train_exploded = pd.concat([ranking_train_exploded.drop(['comments'], axis=1), ranking_train_exploded['comments'].apply(pd.Series).rename(columns={'text':'comments'})], axis=1)"
      ],
      "metadata": {
        "id": "OY-vueQMv1NR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_train_exploded.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wCp9Jjv8hkmV",
        "outputId": "ad987ca1-c7a4-4c0d-f2a1-67cb130071f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  How many summer Y Combinator fundees decided n...   \n",
              "0  How many summer Y Combinator fundees decided n...   \n",
              "\n",
              "                                            comments  score  \n",
              "0  Going back to school is not identical with giv...      0  \n",
              "0  There will invariably be those who don't see t...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffd5fff6-8b2d-45d2-8086-6ce11876a14d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>comments</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>Going back to school is not identical with giv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>There will invariably be those who don't see t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffd5fff6-8b2d-45d2-8086-6ce11876a14d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffd5fff6-8b2d-45d2-8086-6ce11876a14d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffd5fff6-8b2d-45d2-8086-6ce11876a14d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuations = string.punctuation\n",
        "ranking_train_exploded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1cOPQWG9Vj9",
        "outputId": "ee1f3f95-1df5-48b9-de1f-0328e594c1d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(440535, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_train_exploded['polarity'] = ranking_train_exploded['comments'].apply(lambda text: TextBlob(text).sentiment[0])\n",
        "ranking_train_exploded['subjectivity'] = ranking_train_exploded['comments'].apply(lambda text: TextBlob(text).sentiment[1])\n",
        "ranking_train_exploded['num_of_symbols'] = ranking_train_exploded['comments'].apply(len)\n",
        "ranking_train_exploded['num_of_words'] = ranking_train_exploded['comments'].apply(lambda x: len(x.split(sep=' ')))\n",
        "ranking_train_exploded['num_of_stop_words'] = ranking_train_exploded['comments'].apply(lambda x: len(x.split(sep=' '))-len([word for word in x.split(sep=' ') if word not in stop_words]))\n",
        "ranking_train_exploded['percent_of_stop_words_with_all_words'] = ranking_train_exploded['num_of_stop_words']/ranking_train_exploded['num_of_words']\n",
        "ranking_train_exploded['percent_of_len_stop_words'] = 1 - ranking_train_exploded['comments'].apply(lambda x: len(' '.join([word for word in x.split(sep=' ') if word not in stop_words])))/ranking_train_exploded['num_of_symbols']\n",
        "ranking_train_exploded['avg_len_word'] = ranking_train_exploded['num_of_symbols']/ranking_train_exploded['num_of_words']\n",
        "ranking_train_exploded = ranking_train_exploded.drop(['num_of_words'], axis=1)\n",
        "ranking_train_exploded = ranking_train_exploded.drop(['num_of_stop_words'], axis=1)"
      ],
      "metadata": {
        "id": "XKMHL7k5Vb1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = test.head(100000)['comments'].to_list()"
      ],
      "metadata": {
        "id": "1Etn-YVctcWS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_token = FastText(sentences, size=15, window=5, min_count=10, workers=8, sg=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYrYjQsetcZ6",
        "outputId": "2e6c0479-eddc-41e2-bced-68560ff7eb6e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_token.wv['i love VK']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Clhyx4tpEv",
        "outputId": "dc3e2c29-8cc9-44d1-8e1d-6d75a0f5ef4b"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.1751606 ,  0.20864713, -0.04136262, -0.34719867,  0.49617186,\n",
              "       -0.37059578, -0.1569933 , -0.50440276,  0.62647736, -0.14441289,\n",
              "       -0.10911278, -0.81821746,  0.90729654,  1.0385497 ,  0.04335793],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vec(i):\n",
        "  sent = []\n",
        "  k=0\n",
        "  for word in df_shuffled['comments'].iloc[i]:\n",
        "    k+=1\n",
        "    if word:\n",
        "      try: \n",
        "        sent.append(model_token.wv[word])\n",
        "      except:\n",
        "        sent.append(np.zeros(15, dtype=np.float32))\n",
        "    else:\n",
        "      sent.append(np.zeros(15, dtype=np.float32))\n",
        "  return np.mean(sent, axis=0).tolist()"
      ],
      "metadata": {
        "id": "OFvOIdCAtpKd"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ft = pd.read_csv(\"/content/drive/MyDrive/case/train_dataset_features.csv\").set_index('Unnamed: 0')\n",
        "df_ft.head(3)"
      ],
      "metadata": {
        "id": "w8mqhf1TwLLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ft['punctuation'] = df_ft['comments'].apply(lambda x: sum([1 for char in x if char in punctuations]))/df_ft['num_of_symbols']\n",
        "df_ft['sentences'] = df_ft['comments'].apply(lambda x: len(nltk.sent_tokenize(x)))/df_ft['num_of_words']\n",
        "df_ft['connection'] = connect\n",
        "df_ft['symbols_by_avg'] = df_ft['num_of_symbols']/df_ft['num_of_symbols'].mean()\n",
        "df_ft['words_by_avg'] = df_ft['num_of_words']/df_ft['num_of_words'].mean()"
      ],
      "metadata": {
        "id": "3gdiW278I84A"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connect = []\n",
        "for i in range(df_ft.shape[0]):\n",
        "  a = fff(df_ft['comments'].iloc[i])\n",
        "  b = fff(df_ft['text'].iloc[i])\n",
        "  connect.append(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
        "  if i % 30000 == 0:\n",
        "    print('+30k')"
      ],
      "metadata": {
        "id": "wOfsYEf2ZxNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fff(x):\n",
        "  sent = []\n",
        "  for word in x:\n",
        "    try: \n",
        "      sent.append(model_token.wv[word])\n",
        "    except:\n",
        "      sent.append(np.zeros(15, dtype=np.float32))\n",
        "  return np.mean(sent, axis=0)"
      ],
      "metadata": {
        "id": "9Pbvh4x0TmY1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ft.head(3)"
      ],
      "metadata": {
        "id": "TmMSAJwSh7qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ft.to_csv('all_features.csv')"
      ],
      "metadata": {
        "id": "Dn8adFfmhKdb"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаг 2. Токенезирование строк и удаление стоп-слов и лемитизация слов\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "\n",
        "def word_tokenizer(string):\n",
        "    string = html.unescape(string.lower())    # Избавляемя от html-формата записи строк\n",
        "    string = re.sub(r'_', '', string)         # Убираем все нижние подчеркивания\n",
        "    string = re.sub(r'http\\S+', '', string)   # Убираем все ссылки\n",
        "    string = re.sub(r'\\[[0-9]\\]', '', string) # Убираем обозначения номеров ссылок?\n",
        "    \n",
        "    return [lemmatizer.lemmatize(word) for word in tokenizer.tokenize(string) if not word in stop_words]\n",
        "\n",
        "test = copy.deepcopy(ranking_train_exploded)\n",
        "test['text'] = test.apply(lambda row: word_tokenizer(row['text']), axis=1)\n",
        "test['comments'] = test.apply(lambda row: word_tokenizer(row['comments']), axis=1)"
      ],
      "metadata": {
        "id": "K77vQpzeqVRz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['polarity'] = df_ft['polarity']\n",
        "test['subjectivity'] = df_ft['subjectivity']\n",
        "test['num_of_symbols'] = df_ft['num_of_symbols']\n",
        "test['percent_of_len_stop_words'] = df_ft['percent_of_len_stop_words']\n",
        "test['avg_len_word'] = df_ft['avg_len_word']\n",
        "test['punctuation'] = df_ft['punctuation']\n",
        "test['sentences'] = df_ft['sentences']\n",
        "test['connection'] = df_ft['num_of_symbols']\n",
        "test['symbols_by_avg'] = df_ft['symbols_by_avg']\n",
        "test['words_by_avg'] = df_ft['words_by_avg']"
      ],
      "metadata": {
        "id": "pRL1ZiAWcMjA"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# разбиваем датафрейм на группы по 5 строк\n",
        "groups = [test[i:i+5] for i in range(0, len(test), 5)]\n",
        "new_groups = []\n",
        "# перемешиваем каждую группу\n",
        "for group in groups:\n",
        "    new_groups.append(group.sample(frac=1))\n",
        "\n",
        "# объединяем группы обратно в один датафрейм\n",
        "df_shuffled = pd.concat(new_groups)"
      ],
      "metadata": {
        "id": "YE-rHlPME8rB"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.activation(out)\n",
        "        out = self.fc2(out)\n",
        "        out = out + x\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "class RankNet(nn.Module):\n",
        "    def __init__(self, num_inputs, input_dim, hidden_dim, num_outputs):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_outputs = num_outputs\n",
        "        self.blocks = nn.ModuleList([ResNetBlock(input_dim, hidden_dim) for i in range(num_inputs)])\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc1 = nn.Linear(hidden_dim * num_inputs, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_outputs)\n",
        "        \n",
        "    def forward(self, text_vecs_1, text_vecs_2, text_vecs_3, text_vecs_4, text_vecs_5, features):\n",
        "        x1 = self.encoder(text_vecs_1)\n",
        "        x2 = self.encoder(text_vecs_2)\n",
        "        x3 = self.encoder(text_vecs_3)\n",
        "        x4 = self.encoder(text_vecs_4)\n",
        "        x5 = self.encoder(text_vecs_5)\n",
        "        x = torch.stack((x1, x2, x3, x4, x5), dim=1)\n",
        "        x = torch.cat((x, features), dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "c6pX67MHwLq-"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 88107\n",
        "txt_try1 = []\n",
        "for i in range(k):\n",
        "  post = []\n",
        "  for j in range(5):\n",
        "    vec_sent = vec(i*5+j)\n",
        "    try:\n",
        "      if vec_sent[0]+1 != vec_sent[0]+1:\n",
        "        post.append(np.zeros(15, dtype=np.float32).tolist())\n",
        "      else:\n",
        "        if type(vec_sent) != list:\n",
        "          post.append(np.zeros(15, dtype=np.float32).tolist())\n",
        "        else:\n",
        "          post.append(vec_sent)\n",
        "    except:\n",
        "      post.append(np.zeros(15, dtype=np.float32).tolist())\n",
        "  txt_try1.append(post)\n",
        "\n",
        "scores_try1 = [[df_shuffled['score'].iloc[i], df_shuffled['score'].iloc[i+1], df_shuffled['score'].iloc[i+2], df_shuffled['score'].iloc[i+3], df_shuffled['score'].iloc[i+4]] for i in range(0, k*5, 5)]\n",
        "\n",
        "features_try1 = []\n",
        "for j in range(0, k*5, 5):\n",
        "  features_try1.append([[df_shuffled['polarity'].iloc[i], \n",
        "                         df_shuffled['subjectivity'].iloc[i], \n",
        "                         df_shuffled['num_of_symbols'].iloc[i], \n",
        "                         df_shuffled['percent_of_len_stop_words'].iloc[i], \n",
        "                         df_shuffled['avg_len_word'].iloc[i], \n",
        "                         df_shuffled['punctuation'].iloc[i], \n",
        "                         df_shuffled['sentences'].iloc[i], \n",
        "                         df_shuffled['connection'].iloc[i], \n",
        "                         df_shuffled['symbols_by_avg'].iloc[i], \n",
        "                         df_shuffled['words_by_avg'].iloc[i]] for i in range(j, j+5)])"
      ],
      "metadata": {
        "id": "mry7_TzDwLUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51506aef-dcb3-49b2-98d9-6ad05341cd6b"
      },
      "execution_count": 208,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(txt_try1)):\n",
        "  if len(txt_try1[i]) != 5:\n",
        "    print('i=', i)\n",
        "  for j in range(len(txt_try1[i])):\n",
        "    if len(txt_try1[i][j]) != 15:\n",
        "      print('i=', i, 'j=', j)"
      ],
      "metadata": {
        "id": "ZQAMJvt_KXjK"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RankNet(num_inputs=3, input_dim=15, hidden_dim=5, num_outputs=1)\n",
        "criterion = nn.MarginRankingLoss(margin=0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "texts = txt_try1\n",
        "scores = scores_try1\n",
        "features = features_try1\n",
        "\n",
        "dataset = TensorDataset(torch.tensor(texts), torch.tensor(scores), torch.tensor(features))\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    lst_of_ndcg = []\n",
        "    for batch in dataloader:\n",
        "        inputs, targets, features = batch\n",
        "        text_vecs_1, text_vecs_2, text_vecs_3, text_vecs_4, text_vecs_5 = zip(*inputs)\n",
        "        \n",
        "        for n in range(len(batch[0])):\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(text_vecs_1[n], \n",
        "                          text_vecs_2[n], \n",
        "                          text_vecs_3[n], \n",
        "                          text_vecs_4[n], \n",
        "                          text_vecs_5[n], \n",
        "                          features[n].to(torch.float32))\n",
        "          comments = outputs.view(5)\n",
        "          comment_pairs = torch.combinations(outputs.view(-1), 2)\n",
        "          labels = torch.tensor([1 if comments[0] > comments[1] else -1 for i in range(1)] + \n",
        "                                [1 if comments[0] > comments[2] else -1 for i in range(1)] + \n",
        "                                [1 if comments[0] > comments[3] else -1 for i in range(1)] + \n",
        "                                [1 if comments[0] > comments[4] else -1 for i in range(1)] + \n",
        "                                [1 if comments[1] > comments[2] else -1 for i in range(1)] + \n",
        "                                [1 if comments[1] > comments[3] else -1 for i in range(1)] + \n",
        "                                [1 if comments[1] > comments[4] else -1 for i in range(1)] + \n",
        "                                [1 if comments[2] > comments[3] else -1 for i in range(1)] + \n",
        "                                [1 if comments[2] > comments[4] else -1 for i in range(1)] + \n",
        "                                [1 if comments[3] > comments[4] else -1 for i in range(1)])\n",
        "          loss = criterion(comment_pairs[:, 0], comment_pairs[:, 1], labels.float())\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          lst_of_ndcg.append(ndcg_score([targets[n].tolist()], [comments.tolist()], k=5))\n",
        "            \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    print('Epoch {} loss: {:.4f}'.format(epoch+1, epoch_loss))\n",
        "    print('NDCG score: ', np.mean(np.array(lst_of_ndcg)), '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwCa0FE0wLgj",
        "outputId": "d341fb2d-fb05-4f7e-b011-3aca2370a9b6"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 0.0020\n",
            "NDCG score:  0.8852600803315848 \n",
            "\n",
            "Epoch 2 loss: 0.0011\n",
            "NDCG score:  0.8852755859013778 \n",
            "\n",
            "Epoch 3 loss: 0.0009\n",
            "NDCG score:  0.8852619665389597 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "nFW3b522Jdlk"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = scores[:10]\n",
        "\n",
        "#stroka = 53910\n",
        "\n",
        "model = RankNet(num_inputs=3, input_dim=15, hidden_dim=5, num_outputs=1)\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "\n",
        "for stroka in range(10):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      query_scores = model.forward(torch.tensor(txt_try1[stroka][0]),torch.tensor(txt_try1[stroka][1]), torch.tensor(txt_try1[stroka][2]), torch.tensor(txt_try1[stroka][3]), torch.tensor(txt_try1[stroka][4]), torch.tensor(features_try1[stroka], dtype=torch.float32))\n",
        "\n",
        "  sorted_queries = [query for _, query in sorted(zip(query_scores, queries[stroka]), reverse=True)]\n",
        "\n",
        "  #print(list(reversed(sorted_queries)))\n",
        "  print(sorted_queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgFXlGthK_k0",
        "outputId": "a96940e5-0b06-4b34-f5b8-7cf3868eef37"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 3, 1, 2, 0]\n",
            "[3, 4, 2, 1, 0]\n",
            "[4, 1, 0, 3, 2]\n",
            "[4, 3, 2, 1, 0]\n",
            "[0, 4, 3, 2, 1]\n",
            "[3, 1, 4, 2, 0]\n",
            "[4, 1, 3, 2, 0]\n",
            "[1, 0, 2, 4, 3]\n",
            "[4, 3, 2, 1, 0]\n",
            "[3, 0, 1, 2, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op19Ix-LlFgM",
        "outputId": "af018570-f331-42b9-9b5c-521ff8ba8103"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 4, 3, 0],\n",
              " [3, 2, 4, 1, 0],\n",
              " [4, 2, 1, 3, 0],\n",
              " [3, 2, 0, 1, 4],\n",
              " [4, 1, 2, 0, 3],\n",
              " [1, 2, 0, 3, 4],\n",
              " [3, 2, 0, 4, 1],\n",
              " [4, 0, 2, 3, 1],\n",
              " [4, 0, 2, 3, 1],\n",
              " [1, 2, 4, 0, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_test = pd.read_json(\"/content/drive/MyDrive/case/ranking_test.jsonl\", lines=True)"
      ],
      "metadata": {
        "id": "ASidNdEIRXmQ"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаг 1. Преобразование датафрейма\n",
        "ranking_test_exploded = ranking_test.explode('comments')\n",
        "ranking_test_exploded = pd.concat([ranking_test_exploded.drop(['comments'], axis=1), ranking_test_exploded['comments'].apply(pd.Series).rename(columns={'text':'comments'})], axis=1)\n",
        "\n",
        "ranking_test_exploded['polarity'] = ranking_test_exploded['comments'].apply(lambda text: TextBlob(text).sentiment[0])\n",
        "ranking_test_exploded['subjectivity'] = ranking_test_exploded['comments'].apply(lambda text: TextBlob(text).sentiment[1])\n",
        "ranking_test_exploded['num_of_symbols'] = ranking_test_exploded['comments'].apply(len)\n",
        "ranking_test_exploded['num_of_words'] = ranking_test_exploded['comments'].apply(lambda x: len(x.split(sep=' ')))\n",
        "ranking_test_exploded['num_of_stop_words'] = ranking_test_exploded['comments'].apply(lambda x: len(x.split(sep=' '))-len([word for word in x.split(sep=' ') if word not in stop_words]))\n",
        "ranking_test_exploded['percent_of_stop_words_with_all_words'] = ranking_test_exploded['num_of_stop_words']/ranking_test_exploded['num_of_words']\n",
        "ranking_test_exploded['percent_of_len_stop_words'] = 1 - ranking_test_exploded['comments'].apply(lambda x: len(' '.join([word for word in x.split(sep=' ') if word not in stop_words])))/ranking_test_exploded['num_of_symbols']\n",
        "ranking_test_exploded['avg_len_word'] = ranking_test_exploded['num_of_symbols']/ranking_test_exploded['num_of_words']\n",
        "\n",
        "test1 = copy.deepcopy(ranking_test_exploded)\n",
        "\n",
        "test1['text'] = test1.apply(lambda row: word_tokenizer(row['text']), axis=1)\n",
        "test1['comments'] = test1.apply(lambda row: word_tokenizer(row['comments']), axis=1)"
      ],
      "metadata": {
        "id": "_Tuf6FMU89vZ"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_test_exploded['punctuation'] = ranking_test_exploded['comments'].apply(lambda x: sum([1 for char in x if char in punctuations]))/ranking_test_exploded['num_of_symbols']\n",
        "ranking_test_exploded['sentences'] = ranking_test_exploded['comments'].apply(lambda x: len(nltk.sent_tokenize(x)))/ranking_test_exploded['num_of_words']\n",
        "ranking_test_exploded['symbols_by_avg'] = ranking_test_exploded['num_of_symbols']/ranking_test_exploded['num_of_symbols'].mean()\n",
        "ranking_test_exploded['words_by_avg'] = ranking_test_exploded['num_of_words']/ranking_test_exploded['num_of_words'].mean()"
      ],
      "metadata": {
        "id": "7jAXbsI2890s"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1['polarity'] = ranking_test_exploded['polarity']\n",
        "test1['subjectivity'] = ranking_test_exploded['subjectivity']\n",
        "test1['num_of_symbols'] = ranking_test_exploded['num_of_symbols']\n",
        "test1['percent_of_len_stop_words'] = ranking_test_exploded['percent_of_len_stop_words']\n",
        "test1['avg_len_word'] = ranking_test_exploded['avg_len_word']\n",
        "test1['punctuation'] = ranking_test_exploded['punctuation']\n",
        "test1['sentences'] = ranking_test_exploded['sentences']\n",
        "test1['connection'] = ranking_test_exploded['num_of_symbols']\n",
        "test1['symbols_by_avg'] = ranking_test_exploded['symbols_by_avg']\n",
        "test1['words_by_avg'] = ranking_test_exploded['words_by_avg']"
      ],
      "metadata": {
        "id": "yk8-zlEOHC3o"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1.to_csv('test_with_features.csv')"
      ],
      "metadata": {
        "id": "iArQLYzt8-Gr"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vec_test(i):\n",
        "  sent = []\n",
        "  k=0\n",
        "  for word in test1['comments'].iloc[i]:\n",
        "    k+=1\n",
        "    if word:\n",
        "      try: \n",
        "        sent.append(model_token.wv[word])\n",
        "      except:\n",
        "        sent.append(np.zeros(15, dtype=np.float32))\n",
        "    else:\n",
        "      sent.append(np.zeros(15, dtype=np.float32))\n",
        "    # if np.array(sent).shape != (k, 15):\n",
        "    #   print(i)\n",
        "\n",
        "  return np.mean(sent, axis=0).tolist()\n",
        "\n",
        "kk = test1.shape[0]\n",
        "txt_try2 = []\n",
        "for i in range(int(kk/5)):\n",
        "  post = []\n",
        "  for j in range(5):\n",
        "    vec_sent = vec_test(i*5+j)\n",
        "    try:\n",
        "      if vec_sent[0]+1 != vec_sent[0]+1:\n",
        "        post.append(np.zeros(15, dtype=np.float32).tolist())\n",
        "      else:\n",
        "        if type(vec_sent) != list:\n",
        "          post.append(np.zeros(15, dtype=np.float32).tolist())\n",
        "        else:\n",
        "          post.append(vec_sent)\n",
        "    except:\n",
        "      post.append(np.zeros(15, dtype=np.float32).tolist())\n",
        "  txt_try2.append(post)\n",
        "\n",
        "features_try2 = []\n",
        "for j in range(0, kk, 5):\n",
        "  features_try2.append([[test1['polarity'].iloc[i], \n",
        "                         test1['subjectivity'].iloc[i], \n",
        "                         test1['num_of_symbols'].iloc[i], \n",
        "                         test1['percent_of_len_stop_words'].iloc[i], \n",
        "                         test1['avg_len_word'].iloc[i], \n",
        "                         test1['punctuation'].iloc[i], \n",
        "                         test1['sentences'].iloc[i], \n",
        "                         test1['connection'].iloc[i], \n",
        "                         test1['symbols_by_avg'].iloc[i], \n",
        "                         test1['words_by_avg'].iloc[i]] for i in range(j, j+5)])"
      ],
      "metadata": {
        "id": "B6cveRdXHZmD"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/case/ranking_test.jsonl') as f:\n",
        "    lines = f.readlines()"
      ],
      "metadata": {
        "id": "EedK8uXCR9df"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RankNet(num_inputs=3, input_dim=15, hidden_dim=5, num_outputs=1)\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "\n",
        "arr = []\n",
        "\n",
        "for stroka in range(ranking_test.shape[0]):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      query_scores = model.forward(torch.tensor(txt_try2[stroka][0]),torch.tensor(txt_try2[stroka][1]), torch.tensor(txt_try2[stroka][2]), torch.tensor(txt_try2[stroka][3]), torch.tensor(txt_try2[stroka][4]), torch.tensor(features_try2[stroka], dtype=torch.float32))\n",
        "      nums = query_scores.tolist()\n",
        "      nums = nums[0]+nums[1]+nums[2]+nums[3]+nums[4]\n",
        "      x = np.array(nums)\n",
        "      ranked = rankdata(-x, method='dense') - 1\n",
        "      scaled = ranked * (4 / np.max(ranked))\n",
        "      result = scaled.astype(int).tolist()\n",
        "      arr.append(result)\n",
        "arr = np.array(arr)"
      ],
      "metadata": {
        "id": "-HL5BwH5894G"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('uupdated_file.jsonl', 'w') as f: #создаем новый json, где теперь будут скоры с числами\n",
        "    for i, line in enumerate(lines):\n",
        "        obj = json.loads(line.strip())\n",
        "        for j, score in enumerate(arr[i]):\n",
        "            obj['comments'][j]['score'] = int(score)\n",
        "        f.write(json.dumps(obj) + '\\n')"
      ],
      "metadata": {
        "id": "Eo7k9JKRSlhC"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка\n",
        "with open('uupdated_file.jsonl') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "lines[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "DGl8TMz0SbFY",
        "outputId": "67857cbf-6e56-4961-a0a3-98b8e4c3b4cf"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"text\": \"iOS 8.0.1 released, broken on iPhone 6 models, withdrawn\", \"comments\": [{\"text\": \"I&#x27;m still waiting for them to stabilize wifi on the iPad sith iOS 8. Their quality has really started to slip for me since 10.9 on Mac.\", \"score\": 1}, {\"text\": \"For those who upgraded, no need to do a restore. You can just option-click &quot;Update&quot; and downgrade the OS back to 8.0.0.Instructions: https:&#x2F;&#x2F;gist.github.com&#x2F;locriani&#x2F;f0f5f4f71a28945c3750\", \"score\": 2}, {\"text\": \"Upgraded shortly after it was released and suffered the consequences.  Just was able to restore back down to 8.0I had to turn iMessage off and back on again in order for Apple to re-register my number... until then I was unable to send to any existing contacts.\", \"score\": 3}, {\"text\": \"I think they were under a lot of pressure on the HealthKit front.  That was one of their big flagship iOS 8 features, they got all these app developers to integrate it, then iOS 8 shipped and they had a showstopper bug and wouldn&#x27;t release any apps using HealthKit.\", \"score\": 4}, {\"text\": \"Fix for those who already updated:  http:&#x2F;&#x2F;www.imore.com&#x2F;ios-801-kill-touch-id-and-cell-service-...\", \"score\": 0}]}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    }
  ]
}